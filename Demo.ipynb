{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1、可视化DataGeneratorHomographyNet模块都干了什么"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nvidia/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from dataGenerator import DataGeneratorHomographyNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = os.path.join(os.path.expanduser(\"~\"), \"/home/nvidia/test2017\")\n",
    "img_ext = \".jpg\"\n",
    "img_paths = glob.glob(os.path.join(img_dir, '*' + img_ext))\n",
    "dg = DataGeneratorHomographyNet(img_paths, input_dim=(240, 240))\n",
    "data, label = dg.__getitem__(0)\n",
    "for idx in range(dg.batch_size):\n",
    "    cv2.imshow(\"orig\", data[idx, :, :, 0])\n",
    "    cv2.imshow(\"transformed\", data[idx, :, :, 1])\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2、开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from homographyNet import HomographyNet\n",
    "import dataGenerator as dg\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "#取值0,1,2 0-安静模式 1-进度条 2-每一行都有输出\n",
    "verbose = 1\n",
    "#Epoch\n",
    "nb_epo = 150\n",
    "#计时开始\n",
    "start_ts = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "#用于训练的图片目录\n",
    "data_path = \"/home/nvidia/test2017\"\n",
    "#模型保存的目录\n",
    "model_dir = \"/home/nvidia\"\n",
    "img_dir = os.path.join(os.path.expanduser(\"~\"), data_path)\n",
    "model_dir = os.path.join(os.path.expanduser(\"~\"), model_dir, start_ts)\n",
    "#以时间为名创建目录\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nvidia/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/nvidia/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 360, 360, 2)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 360, 360, 64)      1216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 360, 360, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 360, 360, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 360, 360, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 360, 360, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 360, 360, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 180, 180, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 180, 180, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 180, 180, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 180, 180, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 180, 180, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 180, 180, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 180, 180, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 90, 90, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 90, 90, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 90, 90, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 90, 90, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 90, 90, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 90, 90, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 90, 90, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 45, 45, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 45, 45, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 45, 45, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 45, 45, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 45, 45, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 45, 45, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 45, 45, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 22, 22, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 61952)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 61952)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1028)              63687684  \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1028)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 8232      \n",
      "=================================================================\n",
      "Total params: 64,327,596\n",
      "Trainable params: 64,326,060\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_ext = \".jpg\"\n",
    "#获取所有图像目录\n",
    "img_paths = glob.glob(os.path.join(img_dir, '*' + img_ext))\n",
    "input_size = (360, 360, 2)\n",
    "#划分训练集和验证集，验证集搞小一点，不然每个epoch跑完太慢了\n",
    "train_idx, val_idx = train_test_split(img_paths, test_size=0.01)\n",
    "#拿到训练数据\n",
    "train_dg = dg.DataGeneratorHomographyNet(train_idx, input_dim=input_size[0:2], batch_size=batch_size)\n",
    "#拿到既定事实的标签\n",
    "val_dg = dg.DataGeneratorHomographyNet(val_idx, input_dim=input_size[0:2], batch_size=batch_size)\n",
    "#对于神经网络来说这个鬼一样的图就是输入，它自己从这幅图的左边和右边学习出单应性矩阵，神奇吧？\n",
    "#修正网络输入头\n",
    "homo_net = HomographyNet(input_size)\n",
    "#实例化网络结构\n",
    "model = homo_net.build_model()\n",
    "#输出模型\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#检查点回调，没写tensorboard的回调，真正的大师都是直接看loss输出的\n",
    "checkpoint = ModelCheckpoint(\n",
    "    os.path.join(model_dir, 'model.h5'),\n",
    "    monitor='val_loss',\n",
    "    verbose=verbose,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='auto'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      " 1373/20131 [=>............................] - ETA: 1:18:50 - loss: 1615938396204833.0000 - mean_squared_error: 1615938396204833.0000"
     ]
    }
   ],
   "source": [
    "#我嫌弃在上面改太麻烦，直接在这重定义了\n",
    "#开始训练\n",
    "#如果不加steps_per_epoch= 32,  就是每次全跑\n",
    "history = model.fit_generator(train_dg, \n",
    "                              validation_data = val_dg,\n",
    "                              #steps_per_epoch = 32, \n",
    "                              callbacks = [checkpoint], \n",
    "                              epochs = 15, \n",
    "                              verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-cab563c37433>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#整个图看看\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mhistory_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'history.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mhistory_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mhistory_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val_mean_squared_error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "#整个图看看\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.to_csv(os.path.join(model_dir, 'history.csv'))\n",
    "history_df[['loss', 'val_loss']].plot()\n",
    "history_df[['mean_squared_error', 'val_mean_squared_error']].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测&评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
